{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5 Model Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "\n",
    "def get_df_from_gcs_blob(blob, bucket='recipe-data-bucket'):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket)\n",
    "\n",
    "    blob = bucket.blob(blob)\n",
    "    blob = blob.download_as_string()\n",
    "    blob = blob.decode()\n",
    "    blob = StringIO(blob)  #tranform bytes to string here\n",
    "    df = pd.read_csv(blob)\n",
    "    return df\n",
    "\n",
    "train_df = get_df_from_gcs_blob('train_only_cal.csv')\n",
    "test_df = get_df_from_gcs_blob('test_only_cal.csv')\n",
    "test_df = test_df.sample(100).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid CUDA OOM, let's only train samples with max length under 120."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['input'].map(str).map(len) < 120].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class T5Dataset:\n",
    "  def __init__(self, inps, outs, tokenizer, inp_max_len, out_max_len):   \n",
    "    self.inps = inps\n",
    "    self.outs = outs\n",
    "    self.tokenizer = tokenizer\n",
    "    self.input_max_len = inp_max_len\n",
    "    self.output_max_len = out_max_len\n",
    "  \n",
    "  def __len__(self):                      # This method retrives the number of item from the dataset\n",
    "    return len(self.inps)\n",
    "\n",
    "  def __getitem__(self, item):             # This method retrieves the item at the specified index item. \n",
    "    inp = str(self.inps[item])\n",
    "    out = str(self.outs[item])\n",
    "\n",
    "    input_tokenize = self.tokenizer(      \n",
    "            inp,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.input_max_len,\n",
    "            padding = 'max_length',\n",
    "            truncation = True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "    output_tokenize = self.tokenizer(\n",
    "            out,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.output_max_len,\n",
    "            padding = 'max_length',\n",
    "            truncation = True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\"\n",
    "            \n",
    "        )\n",
    "    \n",
    "\n",
    "    input_ids = input_tokenize[\"input_ids\"].flatten().to(dtype=torch.long)\n",
    "    attention_mask = input_tokenize[\"attention_mask\"].flatten().to(dtype=torch.long)\n",
    "    output_ids = output_tokenize['input_ids'].flatten().to(dtype=torch.long)\n",
    "\n",
    "    out = {\n",
    "            'input': inp,      \n",
    "            'target': out,\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'target_ids': output_ids\n",
    "        }\n",
    "        \n",
    "    return out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "def train(tokenizer, model, device, loader, optimizer, fp16=True):\n",
    "    losses = []\n",
    "    if fp16: model.half()\n",
    "    model.train()\n",
    "    for _, data in enumerate(loader, 0):\n",
    "        y = data['target_ids'].to(device, dtype = torch.long)\n",
    "        y_ids = y[:, :-1].contiguous()\n",
    "        lm_labels = y[:, 1:].clone().detach()\n",
    "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "        ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
    "        loss = outputs[0]\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if _%10 == 0:\n",
    "            wandb.log({\"Training Loss\": loss.item()})\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return losses\n",
    "\n",
    "def test(tokenizer, model, device, loader, fp16=True):\n",
    "    losses = []\n",
    "    if fp16: model.half()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(loader, 0):\n",
    "            \n",
    "            y = data['target_ids'].to(device, dtype = torch.long)\n",
    "            y_ids = y[:, :-1].contiguous()\n",
    "            lm_labels = y[:, 1:].clone().detach()\n",
    "            lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "            ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "            outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
    "            loss = outputs[0]\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            if _%10 == 0:\n",
    "                wandb.log({\"Validation Loss\": loss.item()})\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def tune(config=None, MOD='./inp_cal_ingred_cal/final', DEVICE='CPU'):\n",
    "    with wandb.init(config=config):\n",
    "        tokenizer = T5Tokenizer.from_pretrained(MOD)\n",
    "        #tokenizer.add_special_tokens({'additional_special_tokens': ['<ingredients>', '<calories>', '<title>', '<directions>']})\n",
    "\n",
    "        train_dataset = T5Dataset(train_df['input'].values, train_df['output'].values, tokenizer, config.inp_max_len, config.out_max_len)\n",
    "        test_dataset = T5Dataset(test_df['input'].values, test_df['output'].values, tokenizer, config.inp_max_len, config.out_max_len)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=config.train_batch_size, num_workers=config.train_num_workers, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=config.test_batch_size, num_workers=config.train_num_workers)\n",
    "\n",
    "        model = T5ForConditionalGeneration.from_pretrained(MOD).to(DEVICE)\n",
    "\n",
    "        opt = torch.optim.Adam(params =  model.parameters(), lr=config.lr)\n",
    "\n",
    "        for epoch in range(config.epochs):\n",
    "            #train_losses = train(tokenizer, model, DEVICE, train_loader, opt, fp16=config.fp16)\n",
    "            test_losses = test(tokenizer, model, DEVICE, test_loader, fp16=config.fp16)\n",
    "            test_loss = sum(test_losses)/len(test_loader)\n",
    "            wandb.log({'loss': test_loss, 'epoch': epoch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'minimize', 'name': 'loss'},\n",
      " 'parameters': {'epochs': {'value': 1},\n",
      "                'fp16': {'values': [True, False]},\n",
      "                'inp_max_len': {'values': [250, 230, 125, 115]},\n",
      "                'lr': {'values': [1e-05, 0.0001, 0.001, 0.01, 1]},\n",
      "                'out_max_len': {'values': [786, 739, 393, 369]},\n",
      "                'test_batch_size': {'values': [1, 4, 8]},\n",
      "                'test_num_workers': {'values': [1, 2, 4]},\n",
      "                'train_batch_size': {'values': [1, 4, 8]},\n",
      "                'train_num_workers': {'values': [1, 2, 4]}}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {'name': 'loss', 'goal': 'minimize'},\n",
    "    'parameters': {\n",
    "        'lr': {'values': [1e-5, 1e-4, 1e-3, 1e-2, 1]},\n",
    "        'fp16': {'values': [True, False]},\n",
    "        'inp_max_len': {'values': [int(train_df['input'].map(len).max()), int(test_df['input'].map(len).max()), int(train_df['input'].map(len).max() / 2), int(test_df['input'].map(len).max() / 2)]},\n",
    "        'out_max_len': {'values': [int(train_df['output'].map(len).max()), int(test_df['output'].map(len).max()), int(train_df['output'].map(len).max() / 2), int(test_df['output'].map(len).max() / 2)]},\n",
    "        'train_batch_size': {'values': [1, 4, 8]},\n",
    "        'test_batch_size': {'values': [1, 4, 8]},\n",
    "        'train_num_workers': {'values': [1, 2, 4]},\n",
    "        'test_num_workers': {'values': [1, 2, 4]},\n",
    "        'epochs': {'value': 100}\n",
    "    }\n",
    "}\n",
    "pprint.pprint(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: w27u6nmd\n",
      "Sweep URL: https://wandb.ai/rl-final-project/recipe-t5/sweeps/w27u6nmd\n",
      "<IPython.core.display.HTML object>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"recipe-t5\")\n",
    "wandb.agent(sweep_id, lambda x: tune(config=sweep_config), count=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
